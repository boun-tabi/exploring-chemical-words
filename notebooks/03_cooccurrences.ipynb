{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from word_identification import WordIdentifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_tokenizer = Tokenizer.from_file('../data/vocab.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "bdb = pd.read_csv('../data/bdb/interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_tokenizer = WordIdentifier.from_file('../data/vocab.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_tokens = {}\n",
    "vocab = set()\n",
    "for row in bdb.iterrows():\n",
    "    doc_id, smiles = row[1]['prot_id'], row[1]['smiles']\n",
    "    smiles_token_ids = sum(chem_tokenizer.identify_words([smiles], out_type='int'), [])\n",
    "    doc_to_tokens[doc_id] = ' '.join([str(number) for number in smiles_token_ids])\n",
    "    vocab |= set(smiles_token_ids)\n",
    "\n",
    "vocab = {str(number) for number in vocab}\n",
    "corpus = list(doc_to_tokens.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gokce\\Anaconda3\\envs\\transformers\\lib\\site-packages\\scipy\\sparse\\_index.py:124: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_model = CountVectorizer(ngram_range=(1,1), token_pattern=r'(?u)\\b\\w+\\b', vocabulary=vocab) # default unigram model \n",
    "X = count_model.fit_transform(corpus)\n",
    "# X[X > 0] = 1 # run this line if you don't want extra within-text cooccurence (see below)\n",
    "Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
    "Xc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\n",
    "print(Xc.todense()) # print out matrix in dense format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_model.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1601, 1601)\n"
     ]
    }
   ],
   "source": [
    "print(Xc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "cx = scipy.sparse.coo_matrix(Xc)\n",
    "cooccurrences = [(chem_tokenizer.tokenizer.id_to_token(i),chem_tokenizer.tokenizer.id_to_token(j),v) for i,j, v in zip(cx.row, cx.col, cx.data) if v != 0]\n",
    "df_cooccurrence = pd.DataFrame.from_records(cooccurrences, columns=['word1', 'word2', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cooccurrence.to_csv('../data/bdb/cooccurrence.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
